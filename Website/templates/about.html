<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>About - BS-Meter</title>

    <!-- Google Font: Roboto -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">

    <style>
        html, body {
            height: 100%;
            margin: 0;
            background-color: #121212;
            color: white;
            font-family: 'Roboto', sans-serif;
        }

        /* Header styling */
        .header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 15px 30px;
            background-color: #1E1E1E;
            border-bottom: 2px solid #333;
        }

        .header a {
            text-decoration: none;
            color: white;
            font-size: 1.2rem;
            font-weight: bold;
            margin-right: 20px;
        }

        .header a:hover {
            color: #3498db;
        }

        .header img {
            height: 40px;
            width: 40px;
            margin-right: 10px;
        }

        /* About title */
        .title {
            text-align: center;
            font-size: 3rem;
            font-weight: bold;
            margin-top: 40px;
            text-transform: uppercase;
            letter-spacing: 2px;
        }

        /* About content */
        .container {
            max-width: 800px;
            margin: 40px auto;
            padding: 20px;
            background-color: #1E1E1E;
            border-radius: 10px;
            box-shadow: 0 4px 10px rgba(255, 255, 255, 0.1);
        }

        .about-text {
            font-size: 1.1rem;
            line-height: 1.8;
            text-align: justify;
        }

        a {
            color: inherit; /* Inherits the text color (white in this case) */
            text-decoration: underline;
        }

        a:hover {
            color: #3498db;
            text-decoration: underline;
        }


<!--        /* Footer */-->
<!--        .footer {-->
<!--            text-align: center;-->
<!--            padding: 15px;-->
<!--            font-size: 0.9rem;-->
<!--            color: #888;-->
<!--            margin-top: 40px;-->
<!--        }-->
    </style>
</head>
<body>

    <!-- Header with navigation -->
    <div class="header">
        <div class="d-flex align-items-center">
            <a href="/">
                <img src="{{ url_for('static', filename='logo.png') }}" alt="Logo">
            </a>
            <a href="/">BS-Meter</a>
            <a href="/about">About</a>
        </div>
    </div>

    <!-- Title -->
    <div class="title">About</div>

    <!-- About Content -->
    <div class="container">
        <p class="about-text">
            The increasing use of large language model (LLM)-based chatbots has raised concerns regarding the accuracy and reliability of their outputs. A central question in this discussion is whether LLM-generated text constitutes bullshit – communication that lacks a fundamental concern for truth. Specifically, do LLM-based chatbots always produce bullshit, or do they only generate it under certain conditions? Furthermore, can bullshit be systematically detected using computational methods, and might such methods be applicable to other domains of discourse?
        </p>
        <p class="about-text">
            Recent research indicates that there are two theoretical perspectives on the relationship between large language models and the production of bullshit. The <strong>fundamentalist approach</strong> argues that chatbots necessarily produce bullshit because their outputs are disconnected from a concern with truth. On the other hand, the <strong>probabilistic position</strong> asserts that chatbots usually produce bullshit, as their training data contains it, and the economic models guiding their deployment emphasize its spread.
        </p>
        <p class="about-text">
            A research paper titled <em><a href="https://arxiv.org/pdf/2411.15129" target="_blank">“Measuring Bullshit in the Language Games played by ChatGPT”</a></em> explored this issue by using statistical text analysis. The researchers contrasted 1,000 scientific publications with pseudo-scientific text generated by ChatGPT. From this dataset, they developed the <strong>Wittgensteinian Language Game Detector (WLGD)</strong> – a model trained to recognize the patterns of bullshit in language.
        </p>
        <p class="about-text">
            These findings have exciting implications for political discussions, journalism, corporate press releases, and beyond. Inspired by this research, our team developed the <strong>BS-Meter</strong> – a tool that applies these methods to offer an intuitive, accessible way to detect bullshit in text.
        </p>
    </div>

<!--    &lt;!&ndash; Footer &ndash;&gt;-->
<!--    <div class="footer">-->
<!--        &copy; 2025 BS-Meter | All Rights Reserved-->
<!--    </div>-->

</body>
</html>
